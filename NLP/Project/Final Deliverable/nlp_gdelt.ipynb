{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59137f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b488605",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6538f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(sdt, edt): # YYYYMMDDHHMMSS\n",
    "    url = 'https://api.gdeltproject.org/api/v2/doc/doc?query=\"COP26\"&mode=artlist&maxrecords=250&startdatetime='+sdt+'&enddatetime='+edt+'&trans=googtrans' \n",
    "    response = requests.get(url)\n",
    "    driver.get(url)\n",
    "    page = response.text\n",
    "    page = driver.page_source\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce43801",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = '202111' #YYYYMM\n",
    "start_day = 1 #DD\n",
    "end_day =2 #DD\n",
    "\n",
    "\n",
    "news=pd.DataFrame(columns=['url', 'arttitle', 'source','date', 'time', 'language', 'country'])\n",
    "\n",
    "for day in range(start_day,end_day+1,1):\n",
    "\n",
    "    for hour in range(0,24,1):\n",
    "\n",
    "        links=pd.DataFrame(columns=['url', 'arttitle', 'source','date', 'time', 'language', 'country'])\n",
    "\n",
    "        start = str.zfill(str(hour),2)\n",
    "        days = str.zfill(str(day),2)\n",
    "        sdt = month+days+start+'0000'\n",
    "        edt = month+days+start+'5959'\n",
    "\n",
    "        page = get_links(sdt, edt)\n",
    "\n",
    "        soup = BeautifulSoup(page, \"html5lib\")\n",
    "\n",
    "        for index, link in enumerate(soup.find_all('a')):\n",
    "            urls = link.get(\"href\")\n",
    "            links.loc[index,'url'] = urls\n",
    "\n",
    "        for index, span in enumerate(soup.find_all(\"span\", class_=\"arttitle\")):\n",
    "            arttitles = span.text\n",
    "            links.loc[index,'arttitle'] = arttitles\n",
    "\n",
    "        for index, span in enumerate(soup.find_all(\"span\", class_=\"sourceinfo\")):\n",
    "            sourceinfos = span.text.split()\n",
    "            links.loc[index,'source'] = sourceinfos[0]\n",
    "            links.loc[index,'date'] = sourceinfos[4]\n",
    "            links.loc[index,'time'] = sourceinfos[5]\n",
    "            links.loc[index,'language'] = sourceinfos[6]\n",
    "            try:\n",
    "                try:\n",
    "                    links.loc[index,'country'] = sourceinfos[7] + \" \" + sourceinfos[8]\n",
    "                except:\n",
    "                    links.loc[index,'country'] = sourceinfos[7]\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        news = news.append(links, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e43e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv('month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c85b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl = pd.read_csv('news_headline_EN.csv', index_col = 0)\n",
    "news_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f69b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular expression library\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace punctuation with a white space and lower case\n",
    "\n",
    "alphanumeric = lambda x: re.sub(r'[^A-Za-z ]+', '', x)\n",
    "lowcase = lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d644fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl['clean'] = news_hl['arttitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl['clean'] = news_hl.clean.map(alphanumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ad86b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_hl.clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl['clean'] = news_hl.clean.map(lowcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f509b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_hl.clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [e[:75]+\"...\" for e in news_hl['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl['sentiment'] = np.nan\n",
    "news_hl['polarity'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86437354",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, hl in enumerate(news_hl['clean']):\n",
    "\n",
    "    news_hl.loc[index,'sentiment'] = TextBlob(hl).sentiment.subjectivity\n",
    "    news_hl.loc[index,'polarity'] = TextBlob(hl).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl.to_csv('news_hl_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b195b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fba85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate stop words when creating the count vectorizer\n",
    "\n",
    "vec = TfidfVectorizer(stop_words='english', min_df=10)\n",
    "# vec = CountVectorizer(stop_words='english', min_df=10)\n",
    "\n",
    "X = vec.fit_transform(news_hl.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tokens = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_words = news_tokens.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4016833",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f77798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ec79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72768bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in news_tokens.columns:\n",
    "#     news_tokens = news_tokens.rename({w: wnl.lemmatize(w)}, axis=1)\n",
    "\n",
    "# takes too long to run - limited benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fca909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(20)\n",
    "news_topics = nmf_model.fit_transform(news_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef385a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(nmf_model.components_.round(3),\n",
    "             index = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20'],\n",
    "             columns = vec.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):           \n",
    "        print('{}: '.format(ix) + ','.join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306bdc88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_topics(nmf_model, vec.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2e11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ix in range(0,20,1):\n",
    "    top_news_topics = pd.DataFrame(news_topics.round(5),\n",
    "             index = label,\n",
    "             columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20'])\n",
    "    print(\"\\nTopic \", ix)\n",
    "    print(top_news_topics.iloc[:, ix].sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ade2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_topics = pd.DataFrame(news_topics.round(5),\n",
    "             columns = ['Fight for Climate Change', \\\n",
    "                        'Net Zero', \\\n",
    "                        'World Leadership', \\\n",
    "                        'Deforestation Pledge', \\\n",
    "                        'Climate Summit Deficiency', \\\n",
    "                        'United Kingdom', \\\n",
    "                        'Climate Action', \\\n",
    "                        'Global Warming', \\\n",
    "                        'Clean Energy', \\\n",
    "                        'Activists', \\\n",
    "                        'Carbon Emissions', \\\n",
    "                        'China', \\\n",
    "                        'Green Living', \\\n",
    "                        'Commitment', \\\n",
    "                        'Greenhouse Gas', \\\n",
    "                        'Climate Conference Kick-off', \\\n",
    "                        'None', \\\n",
    "                        'Fossil Fuel', \\\n",
    "                        'Climate Crisis', \\\n",
    "                        'Greta Thunberg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a308b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl_sent_topic = pd.concat([news_hl, map_topics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_hl_sent_topic.to_csv('news_hl_sent_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_model = ct.Corex(n_hidden=20, words=news_words,vmax_iter=200, verbose=False, seed=1)\n",
    "\n",
    "ct_model.fit(X, words=news_words, docs=news_hl.clean, anchors=[['green', 'living'],['pledge', 'deforestation'], \\\n",
    "                         ['carbon','emissions'], ['human','swan'], ['sea','level'], \\\n",
    "                         ['global','warming'], ['climate', 'change', 'fight'],['climate', 'crisis'], \\\n",
    "                         ['net', 'zero'], 'china', 'action',['united','kingdom'],['blah', 'activist'], \\\n",
    "                         ['clean','energy'],['greenhouse','gas'],['fossil','fuel']], anchor_strength=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all topics from the CorEx topic model\n",
    "ct_topics = ct_model.get_topics()\n",
    "for n,topic in enumerate(ct_topics):\n",
    "    ct_topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(ct_topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,20,1):\n",
    "    top_news_topics = pd.DataFrame(ct_model.get_top_docs(topic=ix, n_docs=20, sort_by='log_prob'))\n",
    "    \n",
    "\n",
    "    print(\"\\nTopic \", ix)\n",
    "    print(top_news_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104a08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
